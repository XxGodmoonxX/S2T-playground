import { useState, useRef, useCallback, useEffect } from 'react';
import { AudioDetectionState, AudioSegmentEvent, AudioDetectionConfig } from '../types/audio';

const DEFAULT_CONFIG: AudioDetectionConfig = {
  volumeThreshold: 0.01, // Èü≥Â£∞Ê§úÂá∫„ÅÆÈñæÂÄ§
  silenceDuration: 1000, // 1Áßí„ÅÆÁÑ°Èü≥„ÅßÈå≤Èü≥ÁµÇ‰∫Ü
  sampleRate: 44100,
};

export const useAudioDetection = (config: Partial<AudioDetectionConfig> = {}) => {
  const finalConfig = { ...DEFAULT_CONFIG, ...config };
  
  const [state, setState] = useState<AudioDetectionState>({
    isListening: false,
    isRecording: false,
    volume: 0,
    error: null,
  });

  const mediaStreamRef = useRef<MediaStream | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const processorRef = useRef<ScriptProcessorNode | null>(null);
  const animationFrameRef = useRef<number>();
  const silenceTimerRef = useRef<number>();
  const isRecordingRef = useRef(false);
  const recordingStartTimeRef = useRef<number>(0);

  // Èü≥ÈáèË®àÁÆó
  const calculateVolume = useCallback((dataArray: Uint8Array): number => {
    let sum = 0;
    for (let i = 0; i < dataArray.length; i++) {
      sum += (dataArray[i] - 128) * (dataArray[i] - 128);
    }
    return Math.sqrt(sum / dataArray.length) / 128;
  }, []);

  // Èü≥Â£∞Âå∫Èñì„Ç§„Éô„É≥„Éà„ÅÆ„É≠„Ç∞Âá∫Âäõ
  const logAudioEvent = useCallback((event: AudioSegmentEvent) => {
    switch (event.type) {
      case 'start':
        console.log('üéôÔ∏è Èü≥Â£∞Âå∫ÈñìÈñãÂßã:', {
          timestamp: new Date(event.timestamp).toISOString(),
          volume: event.volume?.toFixed(4),
        });
        break;
      case 'data':
        console.log('üìä Èü≥Â£∞„Éá„Éº„Çø:', {
          timestamp: new Date(event.timestamp).toISOString(),
          dataLength: event.audioData?.length,
          volume: event.volume?.toFixed(4),
        });
        break;
      case 'end':
        console.log('üîö Èü≥Â£∞Âå∫ÈñìÁµÇ‰∫Ü:', {
          timestamp: new Date(event.timestamp).toISOString(),
          duration: event.timestamp - recordingStartTimeRef.current,
        });
        break;
    }
  }, []);

  // Èü≥Â£∞Âá¶ÁêÜ
  const processAudio = useCallback(() => {
    if (!analyserRef.current) return;

    const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount);
    analyserRef.current.getByteFrequencyData(dataArray);
    
    const volume = calculateVolume(dataArray);
    
    setState((prev: AudioDetectionState) => ({ ...prev, volume }));

    // Èü≥Â£∞Ê§úÂá∫„É≠„Ç∏„ÉÉ„ÇØ
    if (volume > finalConfig.volumeThreshold) {
      // Èü≥Â£∞„ÅåÊ§úÂá∫„Åï„Çå„Åü
      if (!isRecordingRef.current) {
        // Èå≤Èü≥ÈñãÂßã
        isRecordingRef.current = true;
        recordingStartTimeRef.current = Date.now();
        setState((prev: AudioDetectionState) => ({ ...prev, isRecording: true }));
        
        const startEvent: AudioSegmentEvent = {
          type: 'start',
          timestamp: recordingStartTimeRef.current,
          volume,
        };
        logAudioEvent(startEvent);
      }

      // ÁÑ°Èü≥„Çø„Ç§„Éû„Éº„Çí„ÇØ„É™„Ç¢
      if (silenceTimerRef.current) {
        clearTimeout(silenceTimerRef.current);
        silenceTimerRef.current = undefined;
      }

      // Èü≥Â£∞„Éá„Éº„Çø„Ç§„Éô„É≥„Éà
      if (isRecordingRef.current) {
        const dataEvent: AudioSegmentEvent = {
          type: 'data',
          timestamp: Date.now(),
          volume,
        };
        logAudioEvent(dataEvent);
      }
    } else if (isRecordingRef.current) {
      // Èå≤Èü≥‰∏≠„ÅßÁÑ°Èü≥„ÅåÊ§úÂá∫„Åï„Çå„Åü
      if (!silenceTimerRef.current) {
        silenceTimerRef.current = window.setTimeout(() => {
          // Èå≤Èü≥ÁµÇ‰∫Ü
          isRecordingRef.current = false;
          setState((prev: AudioDetectionState) => ({ ...prev, isRecording: false }));
          
          const endEvent: AudioSegmentEvent = {
            type: 'end',
            timestamp: Date.now(),
          };
          logAudioEvent(endEvent);
          
          silenceTimerRef.current = undefined;
        }, finalConfig.silenceDuration);
      }
    }

    animationFrameRef.current = requestAnimationFrame(processAudio);
  }, [calculateVolume, finalConfig.volumeThreshold, finalConfig.silenceDuration, logAudioEvent]);

  // „Éû„Ç§„ÇØ„Ç¢„ÇØ„Çª„ÇπÈñãÂßã
  const startListening = useCallback(async () => {
    try {
      setState((prev: AudioDetectionState) => ({ ...prev, error: null }));

      // „É°„Éá„Ç£„Ç¢„Çπ„Éà„É™„Éº„É†ÂèñÂæó
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: finalConfig.sampleRate,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
        },
      });

      mediaStreamRef.current = stream;

      // Web Audio API „Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      const analyser = audioContext.createAnalyser();
      const microphone = audioContext.createMediaStreamSource(stream);
      
      analyser.fftSize = 2048;
      analyser.smoothingTimeConstant = 0.8;
      
      microphone.connect(analyser);

      audioContextRef.current = audioContext;
      analyserRef.current = analyser;

      setState((prev: AudioDetectionState) => ({ ...prev, isListening: true }));
      
      // Èü≥Â£∞Âá¶ÁêÜÈñãÂßã
      processAudio();

      console.log('üé§ „Éû„Ç§„ÇØ„Ç¢„ÇØ„Çª„ÇπÈñãÂßã');
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : '‰∏çÊòé„Å™„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü';
      setState((prev: AudioDetectionState) => ({ ...prev, error: errorMessage }));
      console.error('„Éû„Ç§„ÇØ„Ç¢„ÇØ„Çª„Çπ„Ç®„É©„Éº:', error);
    }
  }, [finalConfig.sampleRate, processAudio]);

  // ÂÅúÊ≠¢
  const stopListening = useCallback(() => {
    // „Ç¢„Éã„É°„Éº„Ç∑„Éß„É≥„Éï„É¨„Éº„É†„ÇíÂÅúÊ≠¢
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
    }

    // „Çø„Ç§„Éû„Éº„Çí„ÇØ„É™„Ç¢
    if (silenceTimerRef.current) {
      window.clearTimeout(silenceTimerRef.current);
      silenceTimerRef.current = undefined;
    }

    // Èå≤Èü≥‰∏≠„Åß„ÅÇ„Çå„Å∞ÁµÇ‰∫Ü„Ç§„Éô„É≥„Éà„ÇíÁô∫Ë°å
    if (isRecordingRef.current) {
      const endEvent: AudioSegmentEvent = {
        type: 'end',
        timestamp: Date.now(),
      };
      logAudioEvent(endEvent);
    }

    // „É°„Éá„Ç£„Ç¢„Çπ„Éà„É™„Éº„É†„ÇíÂÅúÊ≠¢
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach((track: MediaStreamTrack) => track.stop());
      mediaStreamRef.current = null;
    }

    // Web Audio Context„ÇíÈñâ„Åò„Çã
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    analyserRef.current = null;
    processorRef.current = null;
    isRecordingRef.current = false;

    setState({
      isListening: false,
      isRecording: false,
      volume: 0,
      error: null,
    });

    console.log('üõë „Éû„Ç§„ÇØ„Ç¢„ÇØ„Çª„ÇπÂÅúÊ≠¢');
  }, [logAudioEvent]);

  // „ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó
  useEffect(() => {
    return () => {
      stopListening();
    };
  }, [stopListening]);

  return {
    ...state,
    startListening,
    stopListening,
  };
};